# Sign-Language-MNIST-Problem
A Hand Sign Recognition application using ASL MNIST Dataset(TensorFlow &amp; OpenCV)

<h1>Project Description</h1>
American Sign Language(ASL) is a complete, natural language that has the same linguistic properties as spoken languages, with grammar that differs from English. ASL is expressed by the movement of hands and faces. This dataset consists of 27,455 images of hand signs, each image is of 28 x 28 size and in grayscale format. The dataset format is patterned to match closely with the classic MNIST. Images in the dataset belong to a label from 0–25 representing letters from A-Z(but no cases of 9=J or 25=Z as they involve hand motion). The training data(27,455 cases) and the test data(7,172 cases) are approximately half the size of standard MNIST but otherwise similar to a header row of the label, pixel1, pixel….pixel784. The original hand gesture image data represented multiple users repeating gestures against different backgrounds. The Sign Language MNIST data came from greatly extending the small number (1704) of the color images included as not cropped around the hand region of interest. 


